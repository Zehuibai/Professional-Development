rm(list = ls())
###Install and load required packages
if(!require(tidyverse)) {install.packages("tidyverse"); library(tidyverse)}
if(!require(rbmi)) {install.packages("rbmi"); library(rbmi)}
if(!require(here)) {install.packages("here"); library(here)}
if(!require(knitr)) {install.packages("knitr"); library(knitr)}
if(!require(janitor)) {install.packages("janitor"); library(janitor)}
knitr::opts_chunk$set(echo = TRUE, fig.width = 10, fig.height = 6)
# <!-- ---------------------------------------------------------------------- -->
# <!--                    1. load the required packages                       -->
# <!-- ---------------------------------------------------------------------- -->
## if(!require(psych)){install.packages("psych")}
packages<-c("tidyverse", "kableExtra",
"mmrm",
"gtsummary","inTextSummaryTable",
"Hmisc","htmltools","clinUtils")
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
ipak(packages)
# <!-- ---------------------------------------------------------------------- -->
# <!--                        2. Basic system settings                        -->
# <!-- ---------------------------------------------------------------------- -->
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
getwd()
Sys.setlocale("LC_ALL","English")
## Open the folder
open_folder <-function(dir){
if (.Platform['OS.type'] == "windows"){
shell.exec(dir)
} else {
system(paste(Sys.getenv("R_BROWSER"), dir))
}
}
open_folder(getwd())
## convert backslash to forward slash in R
# gsub('"', "", gsub("\\\\", "/", readClipboard()))
### get the path
# rstudioapi::getSourceEditorContext()$path
# dirname(rstudioapi::getSourceEditorContext()$path)
### set working directory
# getwd()
# setwd("c:/Users/zbai/Desktop")
# Sys.setlocale("LC_ALL","English")
### get the R Version
# paste(R.Version()[c("major", "minor")], collapse = ".")
### convert backslash to forward slash
# scan("clipboard",what="string")
# gsub('"', "", gsub("\\\\", "/", readClipboard()))
## Load all r functions
## The directory where all source code files are saved.
source_code_dir <- "C:/Users/baiz/Downloads/Data-Analyst-with-R/00 R Function/ZB Function/"
file_path_vec <- list.files(source_code_dir, full.names = T)
for(f_path in file_path_vec){source(f_path)}
# <!-- ---------------------------------------------------------------------- -->
# <!--                         3. Import the datasets                         -->
# <!-- ---------------------------------------------------------------------- -->
# <!-- ---------------------------- -->
# <!-- --3.1 Import csv data ------ -->
# <!-- ---------------------------- -->
# pfad <- "~/Desktop/SASUniversityEdition/myfolders/Daten"
# mydata1 <- read.csv(file.path(pfad, "yourcsv_data.csv"),
#                     sep=";",
#                     header=TRUE)
## Import all csv data from folder
# list_csv_files <- list.files(path = "./csvfolder/")
# do.call(rbind, lapply(list_csv_files, function(x) read.csv(x, stringsAsFactors = FALSE)))
# <!-- ---------------------------- -->
# <!-- --3.2 Import xlsx data ----- -->
# <!-- ---------------------------- -->
# library(readxl)
# mydata2 <- read_excel("C:/Users/zbai/Documents/GitHub/R-Projects/SAS/Yimeng/results-text.xlsx")
# <!-- ---------------------------- -->
# <!-- --3.3 Import sas7dbat data - -->
# <!-- ---------------------------- -->
# library(sas7bdat)
# mydata3 <- read.sas7bdat("~/Desktop/SASUniversityEdition/myfolders/Daten/uis.sas7bdat")
## Import all sas7dbat data from SASfolder
# ZB.import.sas.folder("./SASfolder/")
# <!-- ---------------------------- -->
# <!-- --3.4 Import from copyboard --->
# <!-- ---------------------------- -->
# copdat <- read.delim("clipboard")
# Data_D01 <- copdat
# <!-- ---------------------------------------------------------------------- -->
# <!--                           4. Some Tools                                -->
# <!-- ---------------------------------------------------------------------- -->
## To check out vignettes for one specific package
# browseVignettes("sjPlot")      ## sjPlot for Models Summary
# browseVignettes("gtsummary")
# <!-- ---------------------------------------------------------------------- -->
# <!--                           5. Citation                                -->
# <!-- ---------------------------------------------------------------------- -->
# citation("gtsummary")
# <!-- ---------------------------------------------------------------------- -->
rm(list = ls())
# Load the data
data_nomissing <- read_rds(here("./01_Datasets/DiabetesExampleData_nomissing.rds"))
# Load the data
data_nomissing <- read_rds("./01_Datasets/DiabetesExampleData_nomissing.rds")
# Create summary table showing number and percentage of patients with intercurrent event by visit and treatment group
data_nomissing %>%
tabyl(ontrt, visitn, group) %>%
adorn_totals("row") %>%
adorn_percentages("col") %>%
adorn_pct_formatting(digits = 1) %>%
adorn_ns(position = "front")
# Create summary dataset of mean HbA1c change from baseline by visit, group and intercurrent event status
sumResponseByICE <- data_nomissing %>%
group_by(group, visitn, ontrt) %>%
summarize(n = n(),
resMean = mean(hba1cChg), .groups = "keep")
# Create summary dataset of mean HbA1c change from baseline by visit, group and intercurrent event status
sumResponseByICE <- data_nomissing %>%
group_by(group, visitn, ontrt) %>%
dyplr::summarize(n = n(),
resMean = mean(hba1cChg), .groups = "keep")
# Create summary dataset of mean HbA1c change from baseline by visit, group and intercurrent event status
sumResponseByICE <- data_nomissing %>%
group_by(group, visitn, ontrt) %>%
dplyr::summarize(n = n(),
resMean = mean(hba1cChg), .groups = "keep")
# Create summary dataset of mean HbA1c change from baseline by visit, group and intercurrent event status
sumResponseByICE <- data_nomissing %>%
group_by(group, visitn, ontrt) %>%
dplyr::summarize(n = n(),
resMean = mean(hba1cChg), .groups = "keep")
# Create figure showing mean HbA1c change from baseline by visit, group and intercurrent event status
ggplot(data = sumResponseByICE, aes(x = visitn, y = resMean,
linetype = ontrt,
color = group,
group = interaction(group, ontrt))) +
geom_point() +
geom_line() +
scale_linetype_manual(values=c("dashed", "solid")) +
scale_y_continuous(breaks = seq(-1, 0.5, by = 0.25), limits = c(-1.25, 0.5)) +
labs(x = "Visit", y = "Mean HbA1c Change from Baseline",
color = "Group",
linetype = "On Treatment?") +
theme_bw() +
theme(legend.position = "right")
#Perform ANCOVA
results_nomissing <- data_nomissing %>%
filter(visitn==5) %>%
lm(hba1cChg ~ group + hba1cBl,data=.)
summary(results_nomissing)
data_nomissing <- read_rds("./01_Datasets/DiabetesExampleData_missing.rds")
# Create flag to show if patient is on-treatment&study, off-treatment on-study, or off-treatment&study
data_missing <- data_missing %>%
mutate(dispo = case_when(ontrt==1 ~ "On-treatment",
ontrt==0 & !is.na(hba1c) ~ "Off-treatment, on-study",
ontrt==0 & is.na(hba1c) ~ "Off-study"))
data_missing <- read_rds("./01_Datasets/DiabetesExampleData_missing.rds")
# Create flag to show if patient is on-treatment&study, off-treatment on-study, or off-treatment&study
data_missing <- data_missing %>%
mutate(dispo = case_when(ontrt==1 ~ "On-treatment",
ontrt==0 & !is.na(hba1c) ~ "Off-treatment, on-study",
ontrt==0 & is.na(hba1c) ~ "Off-study"))
# Create summary table showing number and percentage of patients with missing data by visit and treatment group
data_missing %>%
tabyl(dispo, visitn, group) %>%
adorn_totals("row") %>%
adorn_percentages("col") %>%
adorn_pct_formatting(digits = 1) %>%
adorn_ns(position = "front")
# Define which imputation method
# Here we use Bayesian multiple imputation with 250 imputed datasets
method <- method_bayes(burn_in = 200,
burn_between = 6,
n_samples = 250,
seed = 123456)
# Create samples for the imputation parameters by running the draws() function
set.seed(123456)
drawObj <- draws(data = data_missing,
data_ice = dat_ice,
vars = vars,
method = method)
# Create tibble with time of treatment discontinuation and
#   the missing data imputation strategy for each subject
# Here we specify jump-to-reference (JR) strategy for all subjects
dat_ice <- data_missing %>%
arrange(subjid, visitn) %>%
filter(ontrt==0) %>%
group_by(subjid) %>%
slice(1) %>%
ungroup() %>%
mutate(strategy = case_when(
group == "ctl" ~ "JR",
group == "trt" ~ "JR" )) %>%
select(subjid, visitn, strategy)
# Define the names of key variables in the dataset
# The specification here will be used in the imputation model
vars <- set_vars(outcome = "hba1cChg",
visit = "visitn",
subjid = "subjid",
group = "group",
covariates = c("hba1cBl*visitn", "group*visitn"),
strategy = "strategy")
# Define which imputation method
# Here we use Bayesian multiple imputation with 250 imputed datasets
method <- method_bayes(burn_in = 200,
burn_between = 6,
n_samples = 250,
seed = 123456)
# Create samples for the imputation parameters by running the draws() function
set.seed(123456)
drawObj <- draws(data = data_missing,
data_ice = dat_ice,
vars = vars,
method = method)
# Impute the data using the imputation model above
# In the dataset `dat_ice` we specified a jump-to-reference strategy
# Now we need to specify for each group what this 'reference' is
# Set reference arm in control group to itself to the control group
# Set reference arm in treatment group to control group
imputeObj <- impute(draws = drawObj,
references = c("trt"="ctl",
"ctl"="ctl"))
# Impute the data using the imputation model above
# In the dataset `dat_ice` we specified a jump-to-reference strategy
# Now we need to specify for each group what this 'reference' is
# Set reference arm in control group to itself to the control group
# Set reference arm in treatment group to control group
imputeObj <- brmi::impute(draws = drawObj,
references = c("trt"="ctl",
"ctl"="ctl"))
# Impute the data using the imputation model above
# In the dataset `dat_ice` we specified a jump-to-reference strategy
# Now we need to specify for each group what this 'reference' is
# Set reference arm in control group to itself to the control group
# Set reference arm in treatment group to control group
imputeObj <- rbmi::impute(draws = drawObj,
references = c("trt"="ctl",
"ctl"="ctl"))
# Fit the analysis model (ANCOVA) on each imputed dataset
# Analysis model includes group and baseline HbA1c as covariates
anaObj <- analyse(imputations = imputeObj,
fun = ancova,
vars = set_vars(outcome = "hba1cChg",
visit = "visitn",
subjid = "subjid",
group = "group",
covariates = "hba1cBl"))
# Pool the results to get treatment effects
# In the output:
# trt_x refers to the difference between control and treatment group at visit x
# lsm_ref_x is the change from baseline in the reference group (control) at visit x
# lsm_alt_x is the change from baseline in the alternative group (treatment) at visit x
poolObj <- pool(results = anaObj, conf.level = 0.95, alternative = "two.sided")
if(!require(tidyverse)) {install.packages("tidyverse"); library(tidyverse)}
if(!require(here)) {install.packages("here"); library(here)}
if(!require(janitor)) {install.packages("janitor"); library(janitor)}
if(!require(knitr)) {install.packages("knitr"); library(knitr)}
if(!require(table1)) {install.packages("table1"); library(table1)}
if(!require(sandwich)) {install.packages("sandwich"); library(sandwich)}
if(!require(mice)) {install.packages("mice"); library(mice)}
if(!require(lmtest)) {install.packages("lmtest"); library(lmtest)}
data_noICE <- read_rds("./01_Datasets/DiabetesExampleData_wide_noICE.rds")
# Create a boxplot showing HbA1c values by visit and treatment group
ggplot(data_noICE %>%
pivot_longer(
cols = c(hba1cBl, hba1c_1, hba1c_2, hba1c_3, hba1c_4, hba1c_5),
names_to = "Visit",
values_to = "hba1c") %>%
mutate(Visit = factor(Visit, levels = c("hba1cBl", "hba1c_1", "hba1c_2", "hba1c_3", "hba1c_4", "hba1c_5"))),
aes(x = Visit, y = hba1c, fill = group)) +
geom_boxplot() +
labs(title = "HbA1c by Treatment Group and Visit",
x = "Visit",
y = "HbA1c",
fill = "Group") +
scale_x_discrete(labels = c("Baseline", 1, 2, 3, 4, 5)) +
theme_minimal()
data_withICE <- read_rds("./01_Datasets/DiabetesExampleData_wide.rds")
# Data post-ICE is not relevant for our analysis. Set any data post-ICE to missing.
data_withICE <- data_withICE %>%
mutate(
hba1c_1 = ifelse(ontrt_1 == 0, NA, hba1c_1),
hba1c_2 = ifelse(ontrt_2 == 0, NA, hba1c_2),
hba1c_3 = ifelse(ontrt_3 == 0, NA, hba1c_3),
hba1c_4 = ifelse(ontrt_4 == 0, NA, hba1c_4),
hba1c_5 = ifelse(ontrt_5 == 0, NA, hba1c_5),
hba1cChg_5 = ifelse(ontrt_5 == 0, NA, hba1cChg_5)
)
# Create summary table showing number and percentage of patients with missing data by visit and treatment group
table1(~ ontrt_1 + ontrt_2 + ontrt_3 + ontrt_4 + ontrt_5 | group, data_withICE)
# Keep only data that will be used in the MI process
# Treatment group, HbA1c at baseline and follow-up visits 1-4, and
#  Change in HbA1C at visit 5 (outcome)
missing.data <- data_withICE[,c(2,8:12,14)]
set.seed(2545)
# Impute sequentially following monotone missingness
MI.data <-
mice(missing.data,
m=100,
method="norm",
printFlag = F,
visitSequence = "monotone",
maxit = 1)
# Fit ANCOVA model to each multiply imputed dataset
fit <- with(MI.data, lm(hba1cChg_5 ~ group + hba1cBl))
#Pool results using Rubin's rules
results_MI <- pool(fit)
summary(results_MI)
# Propensity score for Treatment Adherence at Visit 1
PS <- glm(ontrt_1 ~ group*hba1cBl,
data = data_withICE,
family = "binomial")
# Add weights for Treatment Adherence at Visit 1
# For patients who did not experience the intercurrent event, the weights
#   are given by 1/(probability of experiencing intercurrent event)
#  PS$fitted.values contains the probability that ontrt_1==1 for each patient
# Drop patients who had the intercurrent event at visit 1
IPW.data <- data_withICE %>%
mutate(weights= 1/PS$fitted.values) %>%
filter(ontrt_1==1)
# Check summary statistics of the weights for visit 1
table1(~ weights | group, IPW.data,
render.continuous=c(.="Mean (SD)", .="Median [Min, Max]",.="Sum"))
IPW <- function(data) {
# Visit 1
PS <- glm(ontrt_1 ~ group*hba1cBl,
data = data,
family = "binomial")
IPW.data <- data %>%
mutate(weights= 1/PS$fitted.values) %>%
filter(ontrt_1==1)
# Visits 2 to 5
for (i in 2:5) {
PS <- glm(paste0("ontrt_", i, " ~ group*hba1cBl+group*hba1c_", i-1), data = IPW.data, family = "binomial")
IPW.data <- IPW.data  %>%
mutate(weights = weights/PS$fitted.values) %>%
filter(get(paste0("ontrt_", i)) == 1)
}
results_IPW <- IPW.data %>%
lm(hba1cChg_5 ~ group + hba1cBl,data=.,weights=weights)
return(results_IPW$coefficients[2])
}
# Bootstrap
#Number of bootstrap resamples
n_boot <- 10000
# Store treatment effects from each bootstrap sample
treatment_effects <- numeric(n_boot)
set.seed(6253)
# Run bootstrap
for (i in 1:n_boot) {
success <- FALSE
while (!success) {
# Resample the data with replacement
boot_sample <- data_withICE %>% slice_sample(n=400,replace=TRUE)
result <- tryCatch({
treatment_effects[i] <- IPW(boot_sample)
success <- TRUE  # Mark success if no error/warning
}, warning = function(w) {}, error = function(e) {})
}
}
# Calculate the bootstrap standard error
bootstrap_se <- sd(treatment_effects)
# Print the bootstrap standard error
bootstrap_se
missing.data <- data_withICE[,c(2,8:12,14)]
set.seed(2545)
# Impute sequentially following monotone missingness
MI.data <-
mice::mice(missing.data,
m=100,
method="norm",
printFlag = F,
visitSequence = "monotone",
maxit = 1)
# Fit ANCOVA model to each multiply imputed dataset
fit <- mice::with(MI.data, lm(hba1cChg_5 ~ group + hba1cBl))
# Fit ANCOVA model to each multiply imputed dataset
fit <- with(MI.data, lm(hba1cChg_5 ~ group + hba1cBl))
#Pool results using Rubin's rules
results_MI <- mice::pool(fit)
summary(results_MI)
